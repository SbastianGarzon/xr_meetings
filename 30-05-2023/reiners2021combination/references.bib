@ARTICLE{reiners2021combination,
  AUTHOR={Reiners, Dirk and Davahli, Mohammad Reza and Karwowski, Waldemar and Cruz-Neira, Carolina},   
  
  TITLE={The Combination of Artificial Intelligence and Extended Reality: A Systematic Review},      
  
  JOURNAL={Frontiers in Virtual Reality},      
  
  VOLUME={2},           
  
  YEAR={2021},      
  
  URL={https://www.frontiersin.org/articles/10.3389/frvir.2021.721933},       
  
  DOI={10.3389/frvir.2021.721933},      
  
  ISSN={2673-4192},   
  
  ABSTRACT={Artificial intelligence (AI) and extended reality (XR) differ in their origin and primary objectives. However, their combination is emerging as a powerful tool for addressing prominent AI and XR challenges and opportunities for cross-development. To investigate the AI-XR combination, we mapped and analyzed published articles through a multi-stage screening strategy. We identified the main applications of the AI-XR combination, including autonomous cars, robotics, military, medical training, cancer diagnosis, entertainment, and gaming applications, advanced visualization methods, smart homes, affective computing, and driver education and training. In addition, we found that the primary motivation for developing the AI-XR applications include 1) training AI, 2) conferring intelligence on XR, and 3) interpreting XR- generated data. Finally, our results highlight the advancements and future perspectives of the AI-XR combination.}
}

@article{sewell2008surgical,
author = {Christopher Sewell and Dan Morris and Nikolas H. Blevins and Sanjeev Dutta and Sumit Agrawal and Federico Barbagli and Kenneth Salisbury},
title = {Providing metrics and performance feedback in a surgical simulator},
journal = {Computer Aided Surgery},
volume = {13},
number = {2},
pages = {63-81},
year  = {2008},
publisher = {Taylor & Francis},
doi = {10.3109/10929080801957712},
    note ={PMID: 18317956},
URL = { 
        https://doi.org/10.3109/10929080801957712
},
eprint = { 
        https://doi.org/10.3109/10929080801957712
}
}

@article{marin2018affective,
  title={Affective computing in virtual reality: emotion recognition from brain and heartbeat dynamics using wearable sensors},
  author={Mar{\'\i}n-Morales, Javier and Higuera-Trujillo, Juan Luis and Greco, Alberto and Guixeres, Jaime and Llinares, Carmen and Scilingo, Enzo Pasquale and Alca{\~n}iz, Mariano and Valenza, Gaetano},
  journal={Scientific reports},
  volume={8},
  number={1},
  pages={13657},
  year={2018},
  publisher={Nature Publishing Group UK London}
}

@article{sadeghi2021lung,
title = {Virtual reality and artificial intelligence for 3-dimensional planning of lung segmentectomies},
journal = {JTCVS Techniques},
volume = {7},
pages = {309-321},
year = {2021},
issn = {2666-2507},
doi = {https://doi.org/10.1016/j.xjtc.2021.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S2666250721002534},
author = {Amir H. Sadeghi and Alexander P.W. M. Maat and Yannick J.H. J. Taverne and Robin Cornelissen and Anne-Marie C. Dingemans and Ad J.J. C. Bogers and Edris A.F. Mahtab},
keywords = {virtual reality, preoperative planning, segmentectomy, video-assisted thoracoscopic surgery, lung cancer},
abstract = {Background
There has been an increasing trend toward pulmonary segmentectomies to treat early-stage lung cancer, small intrapulmonary metastases, and localized benign pathology. A complete preoperative understanding of pulmonary anatomy is essential for accurate surgical planning and case selection. Identifying intersegmental divisions is extremely difficult when performed on computed tomography. For the preoperative planning of segmentectomies, virtual reality (VR) and artificial intelligence could allow 3-dimensional visualization of the complex anatomy of pulmonary segmental divisions, vascular arborization, and bronchial anatomy. This technology can be applied by surgeons preoperatively to gain better insight into a patient's anatomy for planning segmentectomy.
Methods
In this prospective observational pilot study, we aim to assess and demonstrate the technical feasibility and clinical applicability of the first dedicated artificial intelligence-based and immersive 3-dimensional-VR platform (PulmoVR; jointly developed and manufactured by Department of Cardiothoracic Surgery [Erasmus Medical Center, Rotterdam, The Netherlands], MedicalVR [Amsterdam, The Netherlands], EVOCS Medical Image Communication [Fysicon BV, Oss, The Netherlands], and Thirona [Nijmegen, The Netherlands]) for preoperative planning of video-assisted thoracoscopic segmentectomies.
Results
A total of 10 eligible patients for segmentectomy were included in this study after referral through the institutional thoracic oncology multidisciplinary team. PulmoVR was successfully applied as a supplementary imaging tool to perform video-assisted thoracoscopic segmentectomies. In 40% of the cases, the surgical strategy was adjusted due to the 3-dimensional-VR–based evaluation of anatomy. This underlines the potential benefit of additional VR-guided planning of segmentectomy for both surgeon and patient.
Conclusions
Our study demonstrates the successful development and clinical application of the first dedicated artificial intelligence and VR platform for the planning of pulmonary segmentectomy. This is the first study that shows an immersive virtual reality-based application for preoperative planning of segmentectomy to the best of our knowledge.}
}

@InProceedings{shah2018autonomous,
author="Shah, Shital
and Dey, Debadeepta
and Lovett, Chris
and Kapoor, Ashish",
editor="Hutter, Marco
and Siegwart, Roland",
title="AirSim: High-Fidelity Visual and Physical Simulation for Autonomous Vehicles",
booktitle="Field and Service Robotics",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="621--635",
abstract="Developing and testing algorithms for autonomous vehicles in real world is an expensive and time consuming process. Also, in order to utilize recent advances in machine intelligence and deep learning we need to collect a large amount of annotated training data in a variety of conditions and environments. We present a new simulator built on Unreal Engine that offers physically and visually realistic simulations for both of these goals. Our simulator includes a physics engine that can operate at a high frequency for real-time hardware-in-the-loop (HITL) simulations with support for popular protocols (e.g. MavLink). The simulator is designed from the ground up to be extensible to accommodate new types of vehicles, hardware platforms and software protocols. In addition, the modular design enables various components to be easily usable independently in other projects. We demonstrate the simulator by first implementing a quadrotor as an autonomous vehicle and then experimentally comparing the software components with real-world flights.",
isbn="978-3-319-67361-5"
}

@ARTICLE{skarbez2019analytics,
  
AUTHOR={Skarbez, Richard and Polys, Nicholas F. and Ogle, J. Todd and North, Chris and Bowman, Doug A.},   
	 
TITLE={Immersive Analytics: Theory and Research Agenda},      
	
JOURNAL={Frontiers in Robotics and AI},      
	
VOLUME={6},           
	
YEAR={2019},      
	  
URL={https://www.frontiersin.org/articles/10.3389/frobt.2019.00082},       
	
DOI={10.3389/frobt.2019.00082},      
	
ISSN={2296-9144},   
   
ABSTRACT={Advances in a variety of computing fields, including “big data,” machine learning, visualization, and augmented/mixed/virtual reality, have combined to give rise to the emerging field of immersive analytics, which investigates how these new technologies support analysis and decision making. Thus far, we feel that immersive analytics research has been somewhat ad hoc, possibly owing to the fact that there is not yet an organizing framework for immersive analytics research. In this paper, we address this lack by proposing a definition for immersive analytics and identifying some general research areas and specific research questions that will be important for the development of this field. We also present three case studies that, while all being examples of what we would consider immersive analytics, present different challenges, and opportunities. These serve to demonstrate the breadth of immersive analytics and illustrate how the framework proposed in this paper applies to practical research.}
}
